{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -    %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print(f\"data has {data_size:d} characters, {vocab_size:d} unique.\")\n",
    "\n",
    "        self.stoi = { ch: i for i, ch in enumerate(chars) }\n",
    "        self.itos = { i: ch for i, ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx+self.block_size+1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128  # spacial extent of the model for its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 3250633 characters, 119 unique.\n"
     ]
    }
   ],
   "source": [
    "# text = open('/home/grads/xiaohan/scratch/minGPT/data/The Old Man and the Sea.txt', 'r').read()\n",
    "text = open('/home/grads/xiaohan/scratch/minGPT/data/135.txt', 'r').read()\n",
    "train_dataset = CharDataset(text, block_size = 128) # one line of poem is roughly 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/09/2023 18:58:28 - INFO - mingpt.model -    number of parameters: 12797952\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "\n",
    "\n",
    "mconf = GPTConfig(\n",
    "    train_dataset.vocab_size,\n",
    "    train_dataset.block_size,\n",
    "    n_layer=4,\n",
    "    n_head=8,\n",
    "    n_embd=512,\n",
    ")\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/6349 [00:00<?, ?it/s]/home/grads/xiaohan/scratch/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 1 iter 6348: train loss 0.70582, lr 3.000058e-04: 100%|█| 6349/6349 [10:14<00:00, 10.3\n",
      "epoch 2 iter 6348: train loss 0.55222, lr 6.000000e-05: 100%|████████████| 6349/6349 [10:12<00:00, 10.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=2,\n",
    "    batch_size=512,\n",
    "    learning_rate=6e-4,\n",
    "    lr_decay=True,\n",
    "    warmup_tokens=512*20,\n",
    "    final_tokens=2*len(train_dataset)*block_size,\n",
    "    num_workers=4,\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jean Valjean made his appearance in advance of him, which was all\n",
      "sorts of secrets for soldiers, and of which he would have been greatly\n",
      "preserved the appearance of superstition, as in contemplation before he\n",
      "had controlled himself since he had counted on a bickcaxe a spectre\n",
      "of grape-shot had scaled his face; but he had no longer any need of saying\n",
      "either “father” to him. A flash of joy illuminated his whole person\n",
      "who was charged to release him. All these men that they had set out to\n",
      "follow, nevertheless, only he had meant to take her revenge and had\n",
      "called her thoughts.—“This are still bleeding.” She shouted to him:—\n",
      "\n",
      "“Courfeyrac! Courfeyrac! Hohée! He was out! The old man who delivers himself\n",
      "bonnet.”\n",
      "\n",
      "\n",
      "The sewer in a severe space, seemed to be appointed the Bishop as\n",
      "real as he was forced to sell, stepped out, but shutting at his eyes on\n",
      "the stone, and then he perceived a light.\n",
      "\n",
      "While the Bishop was behind the trees with the phantoms, as though\n",
      "enthusiastic over this laughter of a man who is speaking to you. Here is\n",
      "_boffete_, the bread of the law_, the skin of heaven painful; the\n",
      "insurgents with their melancholy outline. Their first are they not\n",
      "conceal themselves. They do not know all these convents, they have\n",
      "a great joy that I am foolish. I have often been here, and they must not\n",
      "attempt to disengage the absolute man who desires to force himself to\n",
      "the situation, had rendered successful, since he had comprehended his\n",
      "conscience, that all this matter had remained there a people. To see\n",
      "them, a little tilbury was more of attention than she was marching in the\n",
      "cafés. And then, over and paid for it with a detachment from the\n",
      "scene, he cried: “Sister, never a precaution on the part of the culvert\n",
      "of the Pont de Jéna, where the merchant’s faint still grimacer\n",
      "has since the preceding evening. He who does not weep does not commune to\n",
      "enclosure. He will not be mentioned. There is no one who listened to\n",
      "Courfeyrac:—\n",
      "\n",
      "“Hey? What’s their mother?”\n",
      "\n",
      "\n",
      "The prisoner laid down the pen and addressed the fe\n"
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level Shaespeare\n",
    "from mingpt.utils import sample\n",
    "\n",
    "context = \"Jean Valjean made his appearance\"\n",
    "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(trainer.device)\n",
    "y = sample(model, x, 2000, temperature=1.0, sample=True, top_k=10)[0]\n",
    "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
